{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/Prompt Engineering.png\" height=\"300\">\n",
    "</div>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Prompt Engineering is the process of crafting instructions that can be understood and interpreted by an AI model (typically LLMs) to enable it to perform tasks and generate outputs that are accurate and correctly formatted.\n",
    "\n",
    "In laymen terms, *prompt engineering* is a fancy term that describes techniques to converse with LLMs to get expected results.\n",
    "\n",
    "- **Software Engineering** -> Writing instructions in code to get a computer to execute tasks.\n",
    "- **Prompt Engineering**   -> Writing instructions in natural language to get an LLM to execute tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with ChatGPT\n",
    "\n",
    "Although transformers, the technology that powers a majority of the LLMs today was invented by a team of Google Researchers in 2017 (we strongly suggest you try to give their seminal paper [Attention is all you need](https://arxiv.org/abs/1706.03762) a read), it was not until the launch of ChatGPT by OpenAI in late 2021 that the people and organizations started grasping the massive potential of LLMs.\n",
    "\n",
    "<br />\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/ChatGPT.png\" height=\"450\">\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "One of the reasons why ChatGPT blew up was because of the launch of a web app that made it incredibly simple to *chat* with an LLM, and get inputs on virtually anything, from drafting cover letters for job applications to debugging code to generating imaginative interviews on Steve Jobs' reaction to the AirPods.\n",
    "\n",
    "### Poll\n",
    "\n",
    "How many of you here have used ChatGPT to accomplish tasks in your day-to-day life? Let us know in the chat!\n",
    "\n",
    "## The OpenAI API\n",
    "\n",
    "While the ChatGPT web app is really impressive, what helps software engineers, designers and entrepreneurs around the world unleash ChatGPT to its fullest is the OpenAI API. Using the OpenAI API and clever prompt engineering, hundreds of startups have come up with innovative products that have the potential to disrupt several industries and pave way for the next trillion dollar companies.\n",
    "\n",
    "Some examples include:\n",
    "\n",
    "#### Perplexity AI: A Search Engine powered by LLMs.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/Perplexity.png\" height=\"400\">\n",
    "</div>\n",
    "\n",
    "#### Shepherd: Empowering Students to learn using GenAI\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/Shepherd.png\" height=\"400\">\n",
    "</div>\n",
    "\n",
    "#### CodeAnt: Fixing bad/buggy code using GenAI\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/Codeant.png\" height=\"400\">\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "\n",
    "And it's not the just the startups. Organizations from virtually every indsutry in the world, be it banking, insurance, CPG, advertising, or pharmaceuticals are also experimenting with GenAI to create new revenue streams, and improve efficiency of their various stakeholders.\n",
    "\n",
    "Here are a few examples of use cases:\n",
    "1. An IT Company leveraging LLMs to resolve tickets.\n",
    "2. A CPG company building a copilot that answers questions using their internal databases.\n",
    "3. An insurance company answering questions using PDF reports.\n",
    "4. A bank performing automated analyses of stocks.\n",
    "...And many more!\n",
    "\n",
    "In all of these cases, powerful results were achieved using ChatGPT through the OpenAI API. Let's see how it works!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisites\n",
    "\n",
    "1. Python and pip installed on your local machine.\n",
    "2. An active OpenAI API key (and optionally, base URL). You can get your own for free at https://platform.openai.com/api-keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the OpenAI package\n",
    "\n",
    "!pip3 install openai\n",
    "!pip3 install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to set your environment variables before running this!\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to set your environment variables before running this!\n",
    "\n",
    "from openai import OpenAI\n",
    "import os \n",
    "\n",
    "# Create an OpenAI client using API key and optionally, the base URL\n",
    "client = OpenAI(\n",
    "    api_key= os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    ")\n",
    "\n",
    "# Ask a question to GPT 3.5\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"Who is the captain of the Indian cricket team?\"}\n",
    "  ],\n",
    "  temperature=0.7,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Components of a ChatGPT Completion Request\n",
    "\n",
    "#### Model\n",
    "\n",
    "You need to decide which model to use. You can find the full list of available models in the [OpenAI API documentation](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4).\n",
    "\n",
    "GPT-4 almost always will provide better performance than GPT-3.5 for every task. The caveat obviously is cost. At the time of writing, using GPT-4 can be over 10x more expensive that GPT-3.5.\n",
    "\n",
    "The rule of thumb is to use GPT-3.5 for smaller, easier tasks and GPT-4 for more complex tasks. Additionally, we strongly recommend testing your applications and code using GPT-3.5 to conserve on costs, and use GPT-4 only in production.\n",
    "\n",
    "#### Messages\n",
    "\n",
    "An array of messages where each message is a dictionary. The dictionary, in turn, contains two keys: the role and the content. There are three roles in ChatGPT:\n",
    "\n",
    "1. **System**: Priming the assistant for a certain task.\n",
    "2. **User**: Messages from the human i.e you.\n",
    "3. **Assistant**: Messages from the AI i.e ChatGPT\n",
    "\n",
    "#### Temperature\n",
    "\n",
    "Temperature determines how creative you want the AI to be. It takes a value between 0 and 1, where 0 represents extremely logical and 1 represents extremely creative.\n",
    "\n",
    "You should use 0 as temperature when using GPT in applications where you want the output to be correct and logical. You can use higher values for temperature when doing more creative tasks (such as creating a digital marketing campaign or brainstorming TikTok trends for your app)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrating a system prompt use\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to ask ChatGPT a question\n",
    "def ask_chatgpt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful chatbot that executes instructions correctly\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_chatgpt(\"Who played the role of Jack in Titanic?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Prompt Engineering Tasks\n",
    "\n",
    "### Summarization\n",
    "\n",
    "One of the most common tasks is summarizing a piece of text quickly. The following example has been taken from the *Prompt Engineering Guide*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Antibiotics are a type of medication used to treat bacterial infections. \n",
    "They work by either killing the bacteria or preventing them from reproducing, allowing the bodyâ€™s immune system to fight off the infection. \n",
    "Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. \n",
    "They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
    " \n",
    "Explain the above in one sentence:\n",
    "\"\"\"\n",
    "\n",
    "print(ask_chatgpt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ChatGPT has been trained on almost all conceivable publicly available human knowledge, you can also ask it to summarize famous books, and movies without having to provide the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Give me a summary of Pride and Prejudice by Jane Austen. Keep it within 300 words.\n",
    "\"\"\"\n",
    "\n",
    "print(ask_chatgpt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question and Answering\n",
    "\n",
    "ChatGPT is capable of answering general knowledge questions as we saw in a section above. It is also capable of answering questions from a given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
    " \n",
    "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. \n",
    "There, scientists generated an early version of the antibody, dubbed OKT3. \n",
    "Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. \n",
    "In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    " \n",
    "Question: What was OKT3 originally sourced from?\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(ask_chatgpt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "GPT is exceptional at working as a classifier for niche tasks. If budget permits, GPT can replace the effort required to build special purpose models for a particular task in the short term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classify the following text as positive, negative or neutral.\n",
    "\n",
    "Text: The movie was okay\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(ask_chatgpt(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Common Tasks\n",
    "\n",
    "1. **Information Extraction**: GPT can extract entities for you from a certain piece of text (for example, identify all cities mentioned in *Around the World in 80 days* by Jules Verne)\n",
    "2. **Coding**: GPT can write complex programs if provided sufficient instruction (for example, implement Djikstra's algorithm in Python).\n",
    "3. **Evaluation**: You can use GPT to evaluate a piece of text on certain criteria. In fact, GPT can evaluate texts that it has generated itself! This technique is heavily used to evaluate quality of GPT outputs and check for hallucinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of a Prompt\n",
    "\n",
    "Depending on the task that needs to be accomplished, a prompt has one or more of the following components:\n",
    "\n",
    "1. **Priming**: An archetype that the model should behave like or who the model should try to emulate \n",
    "2. **Instruction**: What you want the model to perform or achieve.\n",
    "3. **Context**: Information that can help the model get better performance\n",
    "3. **Input**: Input data that will help the model execute the instruction\n",
    "4. **Output Format**: Expected format of the final output\n",
    "5. **Examples:** Possible questions and their correct answers\n",
    "\n",
    "\n",
    "Obviously not all tasks will require all the components described above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Prompt Engineering\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/Reward.png\" height=\"300\">\n",
    "</div>\n",
    "\n",
    "#### Prime GPT using system prompts\n",
    "\n",
    "GPT performs better when asked to assume a certain archetype. For example, if you're asking a finance question, prime GPT using something like *You are a corporate finance officer at Harvard Business School who had a distinguished career as an investment banker at Goldman Sachs*.\n",
    "\n",
    "#### Tip/Punish the GPT\n",
    "\n",
    "If you feel like GPT is not following the instructions you're giving, you can actually pretend to give it positive or negative reinforcement. Examples include *I'll give you $100 if you get this correct in the first try* or *You will be jailed if you get this wrong*. In a professional setting, obviously tilt more towards positive rewards!\n",
    "\n",
    "#### Provide sufficient context\n",
    "\n",
    "The more complex the task is, the more context you need to provide GPT. This includes information such as dos, don'ts, common pitfalls, etc. We will see more of this in the examples.\n",
    "\n",
    "#### Step by Step Instruction\n",
    "\n",
    "If a task is too complex for GPT to do all at once, one way to improve performance is by breaking down a complex task into smaller sub-tasks that are easier and more digestible.\n",
    "\n",
    "#### Few Shot Prompting\n",
    "\n",
    "One of the most popular prompt engineering techniques is called *few shot prompting* where you give examples and their correct answers for GPT to deduce what is actually being expected.\n",
    "\n",
    "\n",
    "Finally, remember that GPT is extremely obedient and resourceful but not very smart (yet). The best results are obtained when you make decisions for GPT or give it a concrete, no-nonsense framework to do so on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Walkthrough 1: 20 Questions\n",
    "\n",
    "Let's use ChatGPT to implement a game of 20 questions!\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/20q.png\" height=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Walkthrough 2: SQL Generator\n",
    "\n",
    "Let's teach GPT to generate SQL statements given a schema.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/sql.png\" height=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Walkthrough 3: Go-to-Market Strategy\n",
    "\n",
    "Use ChatGPT and CrewAI to automate an entire division of marketing and strategy.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"images/GTM.png\" height=\"300\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
